{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jhzhang07/tesP/blob/master/task_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yiw9uAmw2MYF",
        "outputId": "332cd543-239f-45df-d098-17b830ae2c25"
      },
      "id": "Yiw9uAmw2MYF",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install torchinfo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0k0OgP9aceX6",
        "outputId": "5c2b43ba-3cfb-4ea6-cf7c-f920f88b9484"
      },
      "id": "0k0OgP9aceX6",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchinfo\n",
            "  Downloading torchinfo-1.8.0-py3-none-any.whl.metadata (21 kB)\n",
            "Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
            "Installing collected packages: torchinfo\n",
            "Successfully installed torchinfo-1.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Default title text\n",
        "import os.path\n",
        "\n",
        "import torch\n",
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/CAS771-Project-main')\n",
        "import matplotlib.pyplot as plt\n",
        "from arguments import Arguments\n",
        "from dataset import DataLoader, create_combined_loader\n",
        "from evaluate import Evaluator\n",
        "from TS_model import ClassifierModel, ConcatModel, EnsembleModel, ClassifierModel_squeezenet1_0, ClassifierModel_2\n",
        "from train import Trainer\n",
        "import torchvision\n",
        "from torchinfo import summary\n",
        "\n",
        "\n",
        "\n",
        "DATA_MODEL_PATH = '/content/drive/MyDrive/CAS771-Project-main/models'\n",
        "\n",
        "MODEL_PARAMETER_LIMIT = 88 * 1e6\n",
        "\n",
        "\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "classifier1_args = Arguments(\n",
        "    train_data='TaskB_fusion_train.pth',\n",
        "    test_data='TaskB_fusion_test.pth',\n",
        "    # train_data='train_dataB_model_1.pth',\n",
        "    # test_data='val_dataB_model_1.pth',\n",
        "    subset=[173, 137, 34, 159, 201],\n",
        "    n_epochs=20,\n",
        "    batch_size=64,\n",
        "    lr=1e-2,\n",
        ")\n",
        "\n",
        "classifier2_args = Arguments(\n",
        "    train_data='TaskB_fusion_train.pth',\n",
        "    test_data='TaskB_fusion_test.pth',\n",
        "    # train_data='train_dataB_model_2.pth',\n",
        "    # test_data='val_dataB_model_2.pth',\n",
        "    subset=[34, 202, 80, 135, 24],\n",
        "    n_epochs=20,\n",
        "    batch_size=64,\n",
        "    lr=1e-2,\n",
        ")\n",
        "\n",
        "classifier3_args = Arguments(\n",
        "    train_data='TaskB_fusion_train.pth',\n",
        "    test_data='TaskB_fusion_test.pth',\n",
        "    # train_data='train_dataB_model_3.pth',\n",
        "    # test_data='val_dataB_model_3.pth',\n",
        "    subset=[173, 202, 130, 124, 125],\n",
        "    n_epochs=20,\n",
        "    batch_size=64,\n",
        "    lr=1e-2,\n",
        ")\n",
        "\n",
        "\n",
        "def main():\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    print(f\"Using device: {device}\")\n",
        "\n",
        "    models = []\n",
        "    test_datasets = []\n",
        "    train_datasets = []\n",
        "\n",
        "\n",
        "    # Train and evaluate three classifiers\n",
        "    for i, args in enumerate([classifier1_args,\n",
        "                              classifier2_args,\n",
        "                              classifier3_args, ]):\n",
        "        model_id = i + 1\n",
        "\n",
        "        dataloader = DataLoader(args=args,\n",
        "                                root=DATA_MODEL_PATH)\n",
        "        train_dataset, train_loader = dataloader.train_dataset_loader()\n",
        "        test_dataset, test_loader = dataloader.test_dataset_loader()\n",
        "\n",
        "\n",
        "        model = ClassifierModel_2(num_classes=len(args.subset)).to(device)\n",
        "        # model = ClassifierModel_squeezenet1_0(num_classes=len(args.subset)).to(device)\n",
        "        trainer = Trainer(args=args,\n",
        "                          loader=train_loader,\n",
        "                          device=device)\n",
        "\n",
        "        print(f\">>> Start training model for classifier{model_id}\")\n",
        "\n",
        "        print(summary(model, input_size=(1, 3, 224, 224)))\n",
        "\n",
        "\n",
        "\n",
        "        trainer.train(model,\n",
        "                      save_path=f'./model{model_id}_trained.pth',\n",
        "                      # comment out the following line to always train before evaluating.\n",
        "                      # always_load=True,\n",
        "                      )\n",
        "        assert count_parameters(model) < MODEL_PARAMETER_LIMIT\n",
        "\n",
        "        evaluator = Evaluator(loader=test_loader,\n",
        "                              device=device)\n",
        "        test_acc = evaluator.evaluate(model)\n",
        "        print(f\"Test accuracy for classifier{model_id} on subset{model_id}: {test_acc:.2f}%\")\n",
        "\n",
        "        # add to globals\n",
        "        models.append(model)\n",
        "        test_datasets.append(test_dataset)\n",
        "        train_datasets.append(train_dataset)\n",
        "\n",
        "    # Unified Model and Evaluation\n",
        "    ensemble_model = EnsembleModel(models[0], models[1], models[2])\n",
        "\n",
        "    # for param in ensemble_model.parameters():\n",
        "    # param.requires_grad = False\n",
        "\n",
        "    # for param in ensemble_model.classifier.parameters():\n",
        "    # param.requires_grad = True\n",
        "\n",
        "    ensemble_model = ensemble_model.to(device)\n",
        "\n",
        "    classifier_unified = Arguments(\n",
        "    train_data='TaskB_fusion_train.pth',\n",
        "    test_data='TaskB_fusion_test.pth',\n",
        "    # subset=[173, 137, 34, 159, 201, 80, 135],\n",
        "    subset=[173, 137, 34, 159, 201,80, 135, 24, 202, 130, 124, 125],\n",
        "    n_epochs=20,\n",
        "    batch_size=64,\n",
        "    lr=1e-2,\n",
        ")\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    print(f\"Using device: {device}\")\n",
        "\n",
        "\n",
        "    # Train and evaluate uni-classifiers\n",
        "    for i, args in enumerate([classifier_unified\n",
        "                           ]):\n",
        "        model_id = i + 1\n",
        "\n",
        "        dataloader = DataLoader(args=args,\n",
        "                                root=DATA_MODEL_PATH)\n",
        "        train_dataset, train_loader = dataloader.train_dataset_loader()\n",
        "        test_dataset, test_loader = dataloader.test_dataset_loader()\n",
        "\n",
        "        # model = ClassifierModel(num_classes=len(args.subset)).to(device)\n",
        "\n",
        "        trainer = Trainer(args=args,\n",
        "                          loader=train_loader,\n",
        "                          device=device)\n",
        "\n",
        "        print(f\">>> Start training model for unified_classifier\")\n",
        "        print(summary(ensemble_model, input_size=(1, 3, 224, 224)))\n",
        "        trainer.train(ensemble_model,\n",
        "                      save_path=f'./unified_model_trained.pth',\n",
        "                      # comment out the following line to always train before evaluating.\n",
        "                      # always_load=True,\n",
        "                      )\n",
        "        assert count_parameters(ensemble_model) < MODEL_PARAMETER_LIMIT\n",
        "\n",
        "        print(count_parameters(ensemble_model))\n",
        "        evaluator = Evaluator(loader=test_loader,\n",
        "                              device=device)\n",
        "        test_acc = evaluator.evaluate(ensemble_model)\n",
        "        print(f\"Test accuracy for unified_classifier on subset: {test_acc:.2f}%\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hXDBPcQO5qug",
        "outputId": "f0ae3f15-ec5a-4d38-ca6c-b1edc4a380ce"
      },
      "id": "hXDBPcQO5qug",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n",
            "Subset train samples: 2500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/mobilenet_v3_large-5c1a4163.pth\" to /root/.cache/torch/hub/checkpoints/mobilenet_v3_large-5c1a4163.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Subset test samples: 200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 21.1M/21.1M [00:00<00:00, 70.4MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">>> Start training model for classifier1\n",
            "=========================================================================================================\n",
            "Layer (type:depth-idx)                                  Output Shape              Param #\n",
            "=========================================================================================================\n",
            "ClassifierModel_2                                       [1, 5]                    --\n",
            "├─MobileNetV3: 1-1                                      [1, 5]                    --\n",
            "│    └─Sequential: 2-1                                  [1, 960, 7, 7]            --\n",
            "│    │    └─Conv2dNormActivation: 3-1                   [1, 16, 112, 112]         (464)\n",
            "│    │    └─InvertedResidual: 3-2                       [1, 16, 112, 112]         (464)\n",
            "│    │    └─InvertedResidual: 3-3                       [1, 24, 56, 56]           (3,440)\n",
            "│    │    └─InvertedResidual: 3-4                       [1, 24, 56, 56]           (4,440)\n",
            "│    │    └─InvertedResidual: 3-5                       [1, 40, 28, 28]           (10,328)\n",
            "│    │    └─InvertedResidual: 3-6                       [1, 40, 28, 28]           (20,992)\n",
            "│    │    └─InvertedResidual: 3-7                       [1, 40, 28, 28]           (20,992)\n",
            "│    │    └─InvertedResidual: 3-8                       [1, 80, 14, 14]           (32,080)\n",
            "│    │    └─InvertedResidual: 3-9                       [1, 80, 14, 14]           (34,760)\n",
            "│    │    └─InvertedResidual: 3-10                      [1, 80, 14, 14]           (31,992)\n",
            "│    │    └─InvertedResidual: 3-11                      [1, 80, 14, 14]           (31,992)\n",
            "│    │    └─InvertedResidual: 3-12                      [1, 112, 14, 14]          (214,424)\n",
            "│    │    └─InvertedResidual: 3-13                      [1, 112, 14, 14]          386,120\n",
            "│    │    └─InvertedResidual: 3-14                      [1, 160, 7, 7]            429,224\n",
            "│    │    └─InvertedResidual: 3-15                      [1, 160, 7, 7]            797,360\n",
            "│    │    └─InvertedResidual: 3-16                      [1, 160, 7, 7]            797,360\n",
            "│    │    └─Conv2dNormActivation: 3-17                  [1, 960, 7, 7]            155,520\n",
            "│    └─AdaptiveAvgPool2d: 2-2                           [1, 960, 1, 1]            --\n",
            "│    └─Sequential: 2-3                                  [1, 5]                    --\n",
            "│    │    └─Linear: 3-18                                [1, 1280]                 1,230,080\n",
            "│    │    └─Hardswish: 3-19                             [1, 1280]                 --\n",
            "│    │    └─Dropout: 3-20                               [1, 1280]                 --\n",
            "│    │    └─Linear: 3-21                                [1, 5]                    6,405\n",
            "=========================================================================================================\n",
            "Total params: 4,208,437\n",
            "Trainable params: 3,802,069\n",
            "Non-trainable params: 406,368\n",
            "Total mult-adds (Units.MEGABYTES): 215.35\n",
            "=========================================================================================================\n",
            "Input size (MB): 0.60\n",
            "Forward/backward pass size (MB): 70.45\n",
            "Params size (MB): 16.83\n",
            "Estimated Total Size (MB): 87.88\n",
            "=========================================================================================================\n",
            "Epoch [1/20], Loss: 1.3654, Acc: 46.68%, LR: 0.00994\n",
            "Epoch [2/20], Loss: 0.8041, Acc: 70.88%, LR: 0.00976\n",
            "Epoch [3/20], Loss: 0.4550, Acc: 84.12%, LR: 0.00946\n",
            "Epoch [4/20], Loss: 0.2613, Acc: 91.32%, LR: 0.00905\n",
            "Epoch [5/20], Loss: 0.1779, Acc: 93.92%, LR: 0.00854\n",
            "Epoch [6/20], Loss: 0.1517, Acc: 95.36%, LR: 0.00794\n",
            "Epoch [7/20], Loss: 0.1843, Acc: 94.28%, LR: 0.00727\n",
            "Epoch [8/20], Loss: 0.1272, Acc: 95.72%, LR: 0.00655\n",
            "Epoch [9/20], Loss: 0.1248, Acc: 95.88%, LR: 0.00578\n",
            "Epoch [10/20], Loss: 0.0786, Acc: 97.48%, LR: 0.00500\n",
            "Epoch [11/20], Loss: 0.0488, Acc: 98.60%, LR: 0.00422\n",
            "Epoch [12/20], Loss: 0.0567, Acc: 98.16%, LR: 0.00345\n",
            "Epoch [13/20], Loss: 0.0427, Acc: 98.56%, LR: 0.00273\n",
            "Epoch [14/20], Loss: 0.0291, Acc: 99.32%, LR: 0.00206\n",
            "Epoch [15/20], Loss: 0.0344, Acc: 99.32%, LR: 0.00146\n",
            "Epoch [16/20], Loss: 0.0287, Acc: 99.40%, LR: 0.00095\n",
            "Epoch [17/20], Loss: 0.0261, Acc: 99.48%, LR: 0.00054\n",
            "Epoch [18/20], Loss: 0.0240, Acc: 99.56%, LR: 0.00024\n",
            "Epoch [19/20], Loss: 0.0222, Acc: 99.60%, LR: 0.00006\n",
            "Epoch [20/20], Loss: 0.0243, Acc: 99.52%, LR: 0.00000\n",
            "Training Finished\n",
            "Model saved to ./model1_trained.pth\n",
            "Test accuracy for classifier1 on subset1: 72.00%\n",
            "Subset train samples: 2500\n",
            "Subset test samples: 200\n",
            ">>> Start training model for classifier2\n",
            "=========================================================================================================\n",
            "Layer (type:depth-idx)                                  Output Shape              Param #\n",
            "=========================================================================================================\n",
            "ClassifierModel_2                                       [1, 5]                    --\n",
            "├─MobileNetV3: 1-1                                      [1, 5]                    --\n",
            "│    └─Sequential: 2-1                                  [1, 960, 7, 7]            --\n",
            "│    │    └─Conv2dNormActivation: 3-1                   [1, 16, 112, 112]         (464)\n",
            "│    │    └─InvertedResidual: 3-2                       [1, 16, 112, 112]         (464)\n",
            "│    │    └─InvertedResidual: 3-3                       [1, 24, 56, 56]           (3,440)\n",
            "│    │    └─InvertedResidual: 3-4                       [1, 24, 56, 56]           (4,440)\n",
            "│    │    └─InvertedResidual: 3-5                       [1, 40, 28, 28]           (10,328)\n",
            "│    │    └─InvertedResidual: 3-6                       [1, 40, 28, 28]           (20,992)\n",
            "│    │    └─InvertedResidual: 3-7                       [1, 40, 28, 28]           (20,992)\n",
            "│    │    └─InvertedResidual: 3-8                       [1, 80, 14, 14]           (32,080)\n",
            "│    │    └─InvertedResidual: 3-9                       [1, 80, 14, 14]           (34,760)\n",
            "│    │    └─InvertedResidual: 3-10                      [1, 80, 14, 14]           (31,992)\n",
            "│    │    └─InvertedResidual: 3-11                      [1, 80, 14, 14]           (31,992)\n",
            "│    │    └─InvertedResidual: 3-12                      [1, 112, 14, 14]          (214,424)\n",
            "│    │    └─InvertedResidual: 3-13                      [1, 112, 14, 14]          386,120\n",
            "│    │    └─InvertedResidual: 3-14                      [1, 160, 7, 7]            429,224\n",
            "│    │    └─InvertedResidual: 3-15                      [1, 160, 7, 7]            797,360\n",
            "│    │    └─InvertedResidual: 3-16                      [1, 160, 7, 7]            797,360\n",
            "│    │    └─Conv2dNormActivation: 3-17                  [1, 960, 7, 7]            155,520\n",
            "│    └─AdaptiveAvgPool2d: 2-2                           [1, 960, 1, 1]            --\n",
            "│    └─Sequential: 2-3                                  [1, 5]                    --\n",
            "│    │    └─Linear: 3-18                                [1, 1280]                 1,230,080\n",
            "│    │    └─Hardswish: 3-19                             [1, 1280]                 --\n",
            "│    │    └─Dropout: 3-20                               [1, 1280]                 --\n",
            "│    │    └─Linear: 3-21                                [1, 5]                    6,405\n",
            "=========================================================================================================\n",
            "Total params: 4,208,437\n",
            "Trainable params: 3,802,069\n",
            "Non-trainable params: 406,368\n",
            "Total mult-adds (Units.MEGABYTES): 215.35\n",
            "=========================================================================================================\n",
            "Input size (MB): 0.60\n",
            "Forward/backward pass size (MB): 70.45\n",
            "Params size (MB): 16.83\n",
            "Estimated Total Size (MB): 87.88\n",
            "=========================================================================================================\n",
            "Epoch [1/20], Loss: 1.3181, Acc: 48.40%, LR: 0.00994\n",
            "Epoch [2/20], Loss: 0.6655, Acc: 75.52%, LR: 0.00976\n",
            "Epoch [3/20], Loss: 0.3552, Acc: 88.36%, LR: 0.00946\n",
            "Epoch [4/20], Loss: 0.2425, Acc: 91.96%, LR: 0.00905\n",
            "Epoch [5/20], Loss: 0.1593, Acc: 94.92%, LR: 0.00854\n",
            "Epoch [6/20], Loss: 0.1089, Acc: 96.76%, LR: 0.00794\n",
            "Epoch [7/20], Loss: 0.1254, Acc: 96.04%, LR: 0.00727\n",
            "Epoch [8/20], Loss: 0.0621, Acc: 98.52%, LR: 0.00655\n",
            "Epoch [9/20], Loss: 0.0463, Acc: 98.84%, LR: 0.00578\n",
            "Epoch [10/20], Loss: 0.0620, Acc: 97.80%, LR: 0.00500\n",
            "Epoch [11/20], Loss: 0.0704, Acc: 97.68%, LR: 0.00422\n",
            "Epoch [12/20], Loss: 0.0423, Acc: 98.84%, LR: 0.00345\n",
            "Epoch [13/20], Loss: 0.0334, Acc: 99.16%, LR: 0.00273\n",
            "Epoch [14/20], Loss: 0.0289, Acc: 99.20%, LR: 0.00206\n",
            "Epoch [15/20], Loss: 0.0159, Acc: 99.88%, LR: 0.00146\n",
            "Epoch [16/20], Loss: 0.0190, Acc: 99.64%, LR: 0.00095\n",
            "Epoch [17/20], Loss: 0.0196, Acc: 99.48%, LR: 0.00054\n",
            "Epoch [18/20], Loss: 0.0150, Acc: 99.76%, LR: 0.00024\n",
            "Epoch [19/20], Loss: 0.0158, Acc: 99.72%, LR: 0.00006\n",
            "Epoch [20/20], Loss: 0.0113, Acc: 99.84%, LR: 0.00000\n",
            "Training Finished\n",
            "Model saved to ./model2_trained.pth\n",
            "Test accuracy for classifier2 on subset2: 79.50%\n",
            "Subset train samples: 2500\n",
            "Subset test samples: 200\n",
            ">>> Start training model for classifier3\n",
            "=========================================================================================================\n",
            "Layer (type:depth-idx)                                  Output Shape              Param #\n",
            "=========================================================================================================\n",
            "ClassifierModel_2                                       [1, 5]                    --\n",
            "├─MobileNetV3: 1-1                                      [1, 5]                    --\n",
            "│    └─Sequential: 2-1                                  [1, 960, 7, 7]            --\n",
            "│    │    └─Conv2dNormActivation: 3-1                   [1, 16, 112, 112]         (464)\n",
            "│    │    └─InvertedResidual: 3-2                       [1, 16, 112, 112]         (464)\n",
            "│    │    └─InvertedResidual: 3-3                       [1, 24, 56, 56]           (3,440)\n",
            "│    │    └─InvertedResidual: 3-4                       [1, 24, 56, 56]           (4,440)\n",
            "│    │    └─InvertedResidual: 3-5                       [1, 40, 28, 28]           (10,328)\n",
            "│    │    └─InvertedResidual: 3-6                       [1, 40, 28, 28]           (20,992)\n",
            "│    │    └─InvertedResidual: 3-7                       [1, 40, 28, 28]           (20,992)\n",
            "│    │    └─InvertedResidual: 3-8                       [1, 80, 14, 14]           (32,080)\n",
            "│    │    └─InvertedResidual: 3-9                       [1, 80, 14, 14]           (34,760)\n",
            "│    │    └─InvertedResidual: 3-10                      [1, 80, 14, 14]           (31,992)\n",
            "│    │    └─InvertedResidual: 3-11                      [1, 80, 14, 14]           (31,992)\n",
            "│    │    └─InvertedResidual: 3-12                      [1, 112, 14, 14]          (214,424)\n",
            "│    │    └─InvertedResidual: 3-13                      [1, 112, 14, 14]          386,120\n",
            "│    │    └─InvertedResidual: 3-14                      [1, 160, 7, 7]            429,224\n",
            "│    │    └─InvertedResidual: 3-15                      [1, 160, 7, 7]            797,360\n",
            "│    │    └─InvertedResidual: 3-16                      [1, 160, 7, 7]            797,360\n",
            "│    │    └─Conv2dNormActivation: 3-17                  [1, 960, 7, 7]            155,520\n",
            "│    └─AdaptiveAvgPool2d: 2-2                           [1, 960, 1, 1]            --\n",
            "│    └─Sequential: 2-3                                  [1, 5]                    --\n",
            "│    │    └─Linear: 3-18                                [1, 1280]                 1,230,080\n",
            "│    │    └─Hardswish: 3-19                             [1, 1280]                 --\n",
            "│    │    └─Dropout: 3-20                               [1, 1280]                 --\n",
            "│    │    └─Linear: 3-21                                [1, 5]                    6,405\n",
            "=========================================================================================================\n",
            "Total params: 4,208,437\n",
            "Trainable params: 3,802,069\n",
            "Non-trainable params: 406,368\n",
            "Total mult-adds (Units.MEGABYTES): 215.35\n",
            "=========================================================================================================\n",
            "Input size (MB): 0.60\n",
            "Forward/backward pass size (MB): 70.45\n",
            "Params size (MB): 16.83\n",
            "Estimated Total Size (MB): 87.88\n",
            "=========================================================================================================\n",
            "Epoch [1/20], Loss: 1.3730, Acc: 43.32%, LR: 0.00994\n",
            "Epoch [2/20], Loss: 0.8689, Acc: 67.08%, LR: 0.00976\n",
            "Epoch [3/20], Loss: 0.5724, Acc: 78.92%, LR: 0.00946\n",
            "Epoch [4/20], Loss: 0.3729, Acc: 86.64%, LR: 0.00905\n",
            "Epoch [5/20], Loss: 0.2370, Acc: 92.80%, LR: 0.00854\n",
            "Epoch [6/20], Loss: 0.1312, Acc: 95.84%, LR: 0.00794\n",
            "Epoch [7/20], Loss: 0.0807, Acc: 97.68%, LR: 0.00727\n",
            "Epoch [8/20], Loss: 0.0931, Acc: 97.12%, LR: 0.00655\n",
            "Epoch [9/20], Loss: 0.0604, Acc: 98.16%, LR: 0.00578\n",
            "Epoch [10/20], Loss: 0.0996, Acc: 96.92%, LR: 0.00500\n",
            "Epoch [11/20], Loss: 0.0983, Acc: 96.80%, LR: 0.00422\n",
            "Epoch [12/20], Loss: 0.0412, Acc: 99.08%, LR: 0.00345\n",
            "Epoch [13/20], Loss: 0.0651, Acc: 97.92%, LR: 0.00273\n",
            "Epoch [14/20], Loss: 0.0481, Acc: 98.84%, LR: 0.00206\n",
            "Epoch [15/20], Loss: 0.0284, Acc: 99.36%, LR: 0.00146\n",
            "Epoch [16/20], Loss: 0.0215, Acc: 99.72%, LR: 0.00095\n",
            "Epoch [17/20], Loss: 0.0245, Acc: 99.72%, LR: 0.00054\n",
            "Epoch [18/20], Loss: 0.0219, Acc: 99.72%, LR: 0.00024\n",
            "Epoch [19/20], Loss: 0.0224, Acc: 99.56%, LR: 0.00006\n",
            "Epoch [20/20], Loss: 0.0224, Acc: 99.48%, LR: 0.00000\n",
            "Training Finished\n",
            "Model saved to ./model3_trained.pth\n",
            "Test accuracy for classifier3 on subset3: 61.50%\n",
            "Using device: cpu\n",
            "Subset train samples: 6000\n",
            "Subset test samples: 480\n",
            ">>> Start training model for unified_classifier\n",
            "==============================================================================================================\n",
            "Layer (type:depth-idx)                                       Output Shape              Param #\n",
            "==============================================================================================================\n",
            "EnsembleModel                                                [1, 15]                   --\n",
            "├─ClassifierModel_2: 1-1                                     [1, 5]                    --\n",
            "│    └─MobileNetV3: 2-1                                      [1, 5]                    --\n",
            "│    │    └─Sequential: 3-1                                  [1, 960, 7, 7]            2,971,952\n",
            "│    │    └─AdaptiveAvgPool2d: 3-2                           [1, 960, 1, 1]            --\n",
            "│    │    └─Sequential: 3-3                                  [1, 5]                    1,236,485\n",
            "├─ClassifierModel_2: 1-2                                     [1, 5]                    --\n",
            "│    └─MobileNetV3: 2-2                                      [1, 5]                    --\n",
            "│    │    └─Sequential: 3-4                                  [1, 960, 7, 7]            2,971,952\n",
            "│    │    └─AdaptiveAvgPool2d: 3-5                           [1, 960, 1, 1]            --\n",
            "│    │    └─Sequential: 3-6                                  [1, 5]                    1,236,485\n",
            "├─ClassifierModel_2: 1-3                                     [1, 5]                    --\n",
            "│    └─MobileNetV3: 2-3                                      [1, 5]                    --\n",
            "│    │    └─Sequential: 3-7                                  [1, 960, 7, 7]            2,971,952\n",
            "│    │    └─AdaptiveAvgPool2d: 3-8                           [1, 960, 1, 1]            --\n",
            "│    │    └─Sequential: 3-9                                  [1, 5]                    1,236,485\n",
            "├─Linear: 1-4                                                [1, 15]                   240\n",
            "==============================================================================================================\n",
            "Total params: 12,625,551\n",
            "Trainable params: 11,406,447\n",
            "Non-trainable params: 1,219,104\n",
            "Total mult-adds (Units.MEGABYTES): 646.04\n",
            "==============================================================================================================\n",
            "Input size (MB): 0.60\n",
            "Forward/backward pass size (MB): 211.34\n",
            "Params size (MB): 50.50\n",
            "Estimated Total Size (MB): 262.45\n",
            "==============================================================================================================\n",
            "Epoch [1/20], Loss: 0.7407, Acc: 79.52%, LR: 0.00994\n",
            "Epoch [2/20], Loss: 0.1154, Acc: 96.67%, LR: 0.00976\n",
            "Epoch [3/20], Loss: 0.0430, Acc: 98.85%, LR: 0.00946\n",
            "Epoch [4/20], Loss: 0.0349, Acc: 99.00%, LR: 0.00905\n",
            "Epoch [5/20], Loss: 0.0248, Acc: 99.30%, LR: 0.00854\n",
            "Epoch [6/20], Loss: 0.0143, Acc: 99.68%, LR: 0.00794\n",
            "Epoch [7/20], Loss: 0.0115, Acc: 99.73%, LR: 0.00727\n",
            "Epoch [8/20], Loss: 0.0112, Acc: 99.75%, LR: 0.00655\n",
            "Epoch [9/20], Loss: 0.0106, Acc: 99.80%, LR: 0.00578\n",
            "Epoch [10/20], Loss: 0.0076, Acc: 99.83%, LR: 0.00500\n",
            "Epoch [11/20], Loss: 0.0063, Acc: 99.83%, LR: 0.00422\n",
            "Epoch [12/20], Loss: 0.0080, Acc: 99.80%, LR: 0.00345\n",
            "Epoch [13/20], Loss: 0.0063, Acc: 99.90%, LR: 0.00273\n",
            "Epoch [14/20], Loss: 0.0050, Acc: 99.95%, LR: 0.00206\n",
            "Epoch [15/20], Loss: 0.0060, Acc: 99.92%, LR: 0.00146\n",
            "Epoch [16/20], Loss: 0.0058, Acc: 99.83%, LR: 0.00095\n",
            "Epoch [17/20], Loss: 0.0069, Acc: 99.90%, LR: 0.00054\n",
            "Epoch [18/20], Loss: 0.0043, Acc: 99.88%, LR: 0.00024\n",
            "Epoch [19/20], Loss: 0.0063, Acc: 99.85%, LR: 0.00006\n",
            "Epoch [20/20], Loss: 0.0048, Acc: 99.95%, LR: 0.00000\n",
            "Training Finished\n",
            "Model saved to ./unified_model_trained.pth\n",
            "11406447\n",
            "Test accuracy for unified_classifier on subset: 61.04%\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}